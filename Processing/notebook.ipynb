{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "099fb478",
   "metadata": {},
   "source": [
    "# Template Search\n",
    "\n",
    "Given a template image (e.g. `./anchor.png`), can we detect this in the video footage?\n",
    "\n",
    "![Example template](./anchor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487d2bf5",
   "metadata": {},
   "source": [
    "## Part 1: Extract Last Frame From A Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957655c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "def extract_last_frame(video_url:str):\n",
    "\n",
    "     # Read video\n",
    "     assert os.path.exists(video_url), \"Video not found!\"\n",
    "     cap = cv2.VideoCapture(video_url)\n",
    "\n",
    "     # Get last ms\n",
    "     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "     total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "     total_duration_ms = int(total_frames/2)\n",
    "     last_frame_ms = total_duration_ms - 1  # go to the last millisecond\n",
    "     print(f\"fps {fps} total_frames {total_frames} total_duration_ms {total_duration_ms} last_frame_ms {last_frame_ms}\")\n",
    "\n",
    "     cap.set(cv2.CAP_PROP_POS_MSEC, last_frame_ms)\n",
    "     ret, last_frame = cap.read()\n",
    "\n",
    "     while cap.isOpened():\n",
    "          ret, frame = cap.read()\n",
    "          if not ret: break\n",
    "          last_frame = frame\n",
    "\n",
    "     video_file_seperated, video_file_ext_seperated = os.path.splitext(video_url)\n",
    "     last_frame_path =  video_file_seperated + \"_last\" + \".jpg\"\n",
    "     cv2.imwrite(last_frame_path, last_frame)\n",
    "\n",
    "     cap.release()\n",
    "     return last_frame_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "863e2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files_with_extensions(dir:str, extensions):\n",
    "    found_files = []\n",
    "    for root, _, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            _, ext = os.path.splitext(file)\n",
    "            if ext.lower() in [e.lower() for e in extensions]:  # Case-insensitive comparison\n",
    "                found_files.append(os.path.join(root, file))\n",
    "    return found_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72b4dc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps 29.994152083556035 total_frames 1378 total_duration_ms 689 last_frame_ms 688\n",
      "fps 29.96589439021522 total_frames 1274 total_duration_ms 637 last_frame_ms 636\n",
      "fps 30.0 total_frames 1404 total_duration_ms 702 last_frame_ms 701\n",
      "fps 60.00212698075082 total_frames 2821 total_duration_ms 1410 last_frame_ms 1409\n",
      "fps 60.002175568367235 total_frames 2758 total_duration_ms 1379 last_frame_ms 1378\n",
      "fps 30.00800650622732 total_frames 1373 total_duration_ms 686 last_frame_ms 685\n",
      "fps 29.983868076716256 total_frames 1394 total_duration_ms 697 last_frame_ms 696\n",
      "fps 30.0 total_frames 1418 total_duration_ms 709 last_frame_ms 708\n",
      "fps 60.00132016105965 total_frames 2727 total_duration_ms 1363 last_frame_ms 1362\n",
      "fps 60.00218269125832 total_frames 2749 total_duration_ms 1374 last_frame_ms 1373\n",
      "fps 30.00832465367682 total_frames 1365 total_duration_ms 682 last_frame_ms 681\n",
      "fps 29.97476502212632 total_frames 1366 total_duration_ms 683 last_frame_ms 682\n",
      "fps 30.0 total_frames 1419 total_duration_ms 709 last_frame_ms 708\n",
      "fps 60.001758937601686 total_frames 2729 total_duration_ms 1364 last_frame_ms 1363\n",
      "fps 60.001312939013985 total_frames 2742 total_duration_ms 1371 last_frame_ms 1370\n",
      "fps 29.987318903519437 total_frames 1381 total_duration_ms 690 last_frame_ms 689\n",
      "fps 29.94606256742179 total_frames 1388 total_duration_ms 694 last_frame_ms 693\n",
      "fps 30.0 total_frames 1413 total_duration_ms 706 last_frame_ms 705\n",
      "fps 60.00219466695929 total_frames 2734 total_duration_ms 1367 last_frame_ms 1366\n",
      "fps 60.002192261317546 total_frames 2737 total_duration_ms 1368 last_frame_ms 1367\n"
     ]
    }
   ],
   "source": [
    "movie_files = find_files_with_extensions('.', ['.mov','.mp4'])\n",
    "frame_files = [extract_last_frame(f) for f in movie_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee5e029",
   "metadata": {},
   "source": [
    "## Part 2: Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186095b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_template_match(\n",
    "    frame_filename, \n",
    "    template_filename, \n",
    "    min_size=10, \n",
    "    max_size=50, \n",
    "        delta_size=5, \n",
    "        thresh=0.9,\n",
    "        draw_bbox=False,\n",
    "        draw_centers=True,\n",
    "        bbox_color=[0,255,255],\n",
    "        bbox_thickness=1,\n",
    "        verbose=False):\n",
    "    \n",
    "    # Load frame using opencv\n",
    "    frame = cv2.imread(frame_filename)\n",
    "    \n",
    "    # Load template using opencv\n",
    "    template_all = cv2.imread(template_filename, cv2.IMREAD_UNCHANGED)\n",
    "    # Prep boxes list\n",
    "    boxes = []\n",
    "    # Iterate through possible sizes of the template, upwards to half of the size\n",
    "    for p in np.arange(min_size, max_size, delta_size):\n",
    "        # Resize the frame\n",
    "        template_resize = cv2.resize(template_all, (p,p))\n",
    "        # Get particular attributes of the image itself. \n",
    "        # We assume transparency, so we have to separate alpha from bgr\n",
    "        template = template_resize[:,:,0:3]\n",
    "        alpha = template_resize[:,:,3]\n",
    "        alpha = cv2.merge([alpha,alpha,alpha])\n",
    "        # get the width and height of the template\n",
    "        h,w = template.shape[:2]\n",
    "        # Prepare possible locations where the template matches\n",
    "        loc = []\n",
    "        # Find those matches.\n",
    "        res = cv2.matchTemplate(\n",
    "            frame,\n",
    "            template,\n",
    "            cv2.TM_CCORR_NORMED,\n",
    "            mask=alpha\n",
    "        )\n",
    "        # threshold by a \n",
    "        loc = np.where(res >= thresh)\n",
    "        if len(loc) > 0:\n",
    "            for pt in zip(*loc[::-1]):\n",
    "                boxes.append((pt[0],pt[1],pt[0]+w,pt[1]+h, pt[0]+(w/2), pt[1]+(h/2)))\n",
    "\n",
    "    \n",
    "    centers = []\n",
    "    for (x1, y1, x2, y2, cx, cy) in boxes:\n",
    "        #result = cv2.rectangle(result, (x1, y1), (x2, y2), bbox_color, bbox_thickness)\n",
    "        centers.append([cx,cy])\n",
    "\n",
    "    mean_center = np.mean(centers, axis=0)\n",
    "    median_center = np.median(centers, axis=0)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"ESTIMATED MEAN POSITION: {mean_center}\")\n",
    "        print(f\"ESTIMATED MEDIAN POSITION: {median_center}\")\n",
    "    \n",
    "    if draw_bbox or draw_centers:\n",
    "        result = frame.copy()\n",
    "        if draw_bbox:\n",
    "             for (x1, y1, x2, y2, cx, cy) in boxes:\n",
    "                 result = cv2.rectangle(result, (x1, y1), (x2, y2), bbox_color, bbox_thickness)\n",
    "        if draw_centers:\n",
    "            result = cv2.drawMarker(result, (int(mean_center[0]), int(mean_center[1])), (0,255,255),cv2.MARKER_CROSS,20,2)\n",
    "            result = cv2.drawMarker(result, (int(median_center[0]), int(median_center[1])), (255,255,0),cv2.MARKER_TILTED_CROSS,20,2)\n",
    "\n",
    "        # Save resulting image\n",
    "        frame_file_seperated, _ = os.path.splitext(frame_filename)\n",
    "        result_path =  frame_file_seperated + \"_matched\" + \".jpg\"\n",
    "        cv2.imwrite(result_path, result)\n",
    "\n",
    "        return mean_center, median_center, result\n",
    "    \n",
    "    return mean_center, median_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfd66d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTIMATED MEAN POSITION: [1321.48392819  736.82544071]\n",
      "ESTIMATED MEDIAN POSITION: [1321.5  737. ]\n",
      "ESTIMATED MEAN POSITION: [640.80245894 638.72119766]\n",
      "ESTIMATED MEDIAN POSITION: [641. 639.]\n",
      "ESTIMATED MEAN POSITION: [1515.58717088 1027.43089696]\n",
      "ESTIMATED MEDIAN POSITION: [1514. 1019.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m _TEMPLATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./anchor.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m last_centers \u001b[38;5;241m=\u001b[39m [find_template_match(f, _TEMPLATE, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m frame_files]\n",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m _TEMPLATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./anchor.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m last_centers \u001b[38;5;241m=\u001b[39m [\u001b[43mfind_template_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_TEMPLATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m frame_files]\n",
      "Cell \u001b[1;32mIn[10], line 54\u001b[0m, in \u001b[0;36mfind_template_match\u001b[1;34m(frame_filename, template_filename, min_size, max_size, delta_size, thresh, draw_bbox, draw_centers, bbox_color, bbox_thickness, verbose)\u001b[0m\n\u001b[0;32m     51\u001b[0m     centers\u001b[38;5;241m.\u001b[39mappend([cx,cy])\n\u001b[0;32m     53\u001b[0m mean_center \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(centers, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 54\u001b[0m median_center \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mESTIMATED MEAN POSITION: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_center\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\lib\\function_base.py:3927\u001b[0m, in \u001b[0;36mmedian\u001b[1;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[0;32m   3845\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_median_dispatcher)\n\u001b[0;32m   3846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedian\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, overwrite_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   3847\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3848\u001b[0m \u001b[38;5;124;03m    Compute the median along the specified axis.\u001b[39;00m\n\u001b[0;32m   3849\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3925\u001b[0m \n\u001b[0;32m   3926\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_median\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3928\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\lib\\function_base.py:3790\u001b[0m, in \u001b[0;36m_ureduce\u001b[1;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[0;32m   3764\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3765\u001b[0m \u001b[38;5;124;03mInternal Function.\u001b[39;00m\n\u001b[0;32m   3766\u001b[0m \u001b[38;5;124;03mCall `func` with `a` as first argument swapping the axes to use extended\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3787\u001b[0m \n\u001b[0;32m   3788\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3789\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(a)\n\u001b[1;32m-> 3790\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maxis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m out \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   3793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_TEMPLATE = './anchor.png'\n",
    "last_centers = [find_template_match(f, _TEMPLATE, verbose=True) for f in frame_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6676c9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
